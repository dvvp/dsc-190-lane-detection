{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to detect sidewalk based on back projecting the rgb and hsv values.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def sidewalk_detection(img):\n",
    "    img_org = img.copy()\n",
    "    img_untouch = img.copy()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "\n",
    "    # Set the region immediately in front of the vehicle as the region of interest (primary assumption)\n",
    "    a = int(height/2) - 130\n",
    "    b = int(height/2) + 130\n",
    "    c = int(width/2) + 100\n",
    "    d = int(width/2) - 100\n",
    "    roi = img_untouch[d:c, a:b, :]\n",
    "\n",
    "    # Convert RGB to HSV region of interest \n",
    "    roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Obtain desirable RGB and HS threshold values (robust to illumination changes)\n",
    "    roi_r_mean = np.mean(roi[:,:,2].ravel())\n",
    "    roi_g_mean = np.mean(roi[:,:,1].ravel())\n",
    "    roi_b_mean = np.mean(roi[:,:,0].ravel())\n",
    "    roi_h_mean = np.mean(roi_hsv[:,:,0].ravel())\n",
    "    roi_s_mean = np.mean(roi_hsv[:,:,1].ravel())\n",
    "\n",
    "    roi_r_thresh = int(roi_r_mean - 40) \n",
    "    roi_g_thresh = int(roi_g_mean - 30) \n",
    "    roi_b_thresh = int(np.min([roi_b_mean + 60, 255])) \n",
    "    roi_s_thresh = int(np.min([roi_s_mean + 50, 255])) \n",
    "\n",
    "    # Remove Noise and obtain HSV of the original image\n",
    "    img = cv2.medianBlur(img, 7)\n",
    "    img = cv2.GaussianBlur(img, (9,9), 0)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply the threshold levels above to the whole image\n",
    "    img_org[img_org[:,:,0] > roi_b_thresh] = 0\n",
    "    img_org[img_hsv[:,:,1] > roi_s_thresh] = 0\n",
    "    img_org[img[:,:,2] < roi_r_thresh] = 0\n",
    "    img_org[img[:,:,1] < roi_g_thresh] = 0\n",
    "    img_org[img_org[:,:,0] > 0] = 255 \n",
    "\n",
    "    # Define a kernel to smoothen the thresholded image\n",
    "    kernel = np.ones((7, 7), dtype=np.uint8)\n",
    "\n",
    "    # Obtain a uniform threshold by constricting and dilating the thresholded image\n",
    "    mask_erode = cv2.erode(img_org[:,:,2], kernel, iterations=7)\n",
    "    mask_dilate = cv2.dilate(mask_erode, kernel, iterations=8)\n",
    "\n",
    "    # Find the largest contour (sidewalk) in the mask\n",
    "    (contours, _) = cv2.findContours(mask_dilate.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if (len(contours) > 0):\n",
    "        c_max = max(contours, key=cv2.contourArea)\n",
    "        M = cv2.moments(c_max) \n",
    "        peri = cv2.arcLength(c_max, True)\n",
    "        approx = cv2.approxPolyDP(c_max, 0.005 * peri, True)\n",
    "        cv2.drawContours(img_untouch, [approx], -1, (0, 0, 255), -1)\n",
    "\n",
    "    return img_untouch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c596b",
   "metadata": {},
   "source": [
    "Run the below cell to use camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0c764",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "\n",
    "def get_frame(queue):\n",
    "    # Get frame from queue\n",
    "    frame = queue.get()\n",
    "    # Convert frame to OpenCV format and return\n",
    "    return frame.getCvFrame()\n",
    "\n",
    "def get_color_camera(pipeline):\n",
    "    # Configure color camera\n",
    "    color = pipeline.createColorCamera()\n",
    "    \n",
    "    # Set Camera Resolution\n",
    "    color.setResolution(dai.ColorCameraProperties.SensorResolution.THE_720_P)\n",
    "    color.setVideoSize(1280, 720)\n",
    "    \n",
    "    # Make video sharper?\n",
    "    color.initialControl.setSharpness(4)     # range: 0..4, default: 1\n",
    "    color.initialControl.setLumaDenoise(0)   # range: 0..4, default: 1\n",
    "    color.initialControl.setChromaDenoise(0) # range: 0..4, default: 1\n",
    "    \n",
    "    # Get main camera\n",
    "    color.setBoardSocket(dai.CameraBoardSocket.AUTO)\n",
    "    \n",
    "    return color\n",
    "\n",
    "def set_window_size(width, height):\n",
    "    cv2.namedWindow(\"video\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"video\", width, height)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Define a pipeline\n",
    "    dai_pipeline = dai.Pipeline()\n",
    "    \n",
    "    dai_pipeline.setCameraTuningBlobPath('tuning_color_ov9782_wide_fov.bin')\n",
    "    \n",
    "    # Set up main camera\n",
    "    color_main = get_color_camera(dai_pipeline)\n",
    "    \n",
    "    # Set output Xlink for main camera\n",
    "    xout_main = dai_pipeline.createXLinkOut()\n",
    "    xout_main.setStreamName(\"video\")\n",
    "  \n",
    "    # Attach cameras to output Xlink\n",
    "    color_main.video.link(xout_main.input)\n",
    "    \n",
    "    with dai.Device(dai_pipeline) as device:\n",
    "        \n",
    "        set_window_size(640, 400)\n",
    "        \n",
    "        # Get output queues. \n",
    "        video_queue = device.getOutputQueue(name=\"video\", maxSize=1)\n",
    "\n",
    "        # Set display window name\n",
    "        cv2.namedWindow(\"video\")\n",
    "\n",
    "        # Variable used to toggle between three views\n",
    "        view_counter = 0\n",
    "        \n",
    "        # Initiate capture counter\n",
    "        existing_images = [int(file.split('.')[0]) for file in os.listdir(\"capture\") if file.endswith('.jpg')]\n",
    "        if existing_images:\n",
    "            capture_counter = max(existing_images) + 1\n",
    "        else:\n",
    "            capture_counter = 1\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            # Get raw frame\n",
    "            raw_frame = get_frame(video_queue)\n",
    "            \n",
    "            # Get overlayed frame\n",
    "            overlayed_frame = sidewalk_detection(raw_frame)\n",
    "\n",
    "            # Choose the view based on the current counter value\n",
    "            if view_counter == 0:\n",
    "                im_out = raw_frame\n",
    "            else:\n",
    "                im_out = overlayed_frame\n",
    "\n",
    "            # Display output image\n",
    "            cv2.imshow(\"video\", im_out)\n",
    "\n",
    "            # Check for keyboard input\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                # Quit when q is pressed\n",
    "                break\n",
    "            elif key == ord('t'):\n",
    "                # Toggle view when t is pressed\n",
    "                view_counter = (view_counter + 1) % 2\n",
    "            elif key == ord('c'):\n",
    "            # Capture and save images when 'c' is pressed\n",
    "                frame_name = os.path.join(\"capture\", f\"{capture_counter}.jpg\")\n",
    "                cv2.imwrite(frame_name, im_out)\n",
    "                print(f\"Image {capture_counter} captured and saved.\")\n",
    "                capture_counter += 1\n",
    "\n",
    "        # Release the OpenCV window and clean up resources\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6209d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "def overlay_road_boundaries(image_path):\n",
    "    # Load Image as Float\n",
    "    img = img_as_float(io.imread(image_path))\n",
    "\n",
    "    # Perform SLIC\n",
    "    img_seg = slic(img, n_segments=200, compactness=8, convert2lab=True, min_size_factor=0.3)\n",
    "\n",
    "    # Convert the image to uint8 for OpenCV\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Get unique superpixel labels\n",
    "    unique_labels = np.unique(img_seg)\n",
    "\n",
    "    # Create a dictionary to store the average color for each superpixel\n",
    "    average_colors = {}\n",
    "\n",
    "    # Calculate the average color for each superpixel\n",
    "    for label in unique_labels:\n",
    "        mask = (img_seg == label)\n",
    "        average_colors[label] = np.mean(img[mask], axis=0)\n",
    "\n",
    "    # Create an image with superpixel regions shaded in average color\n",
    "    shaded_img = np.zeros_like(img)\n",
    "    for label in unique_labels:\n",
    "        mask = (img_seg == label)\n",
    "        shaded_img[mask] = average_colors[label]\n",
    "\n",
    "    # Display Image with Superpixel Regions Shaded in Average Color using OpenCV\n",
    "    cv2.imshow('Superpixel Regions Shaded', shaded_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = '640px-Road_in_Norway.jpg'\n",
    "overlay_road_boundaries(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510aa82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be25f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
